{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a58af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential #  Sequential model\n",
    "from tensorflow.keras.layers import Dense # Fully connected layers\n",
    "import torch\n",
    "import torch.nn as nn # PyTorch neural network module\n",
    "import torch.optim as optim # Optimizers for training\n",
    "from sklearn.datasets import make_classification # Generate synthetic dataset\n",
    "from sklearn.model_selection import train_test_split # Train-test split\n",
    "from sklearn.preprocessing import StandardScaler # Standardize features\n",
    "\n",
    "\"\"\"\n",
    "TensorFlow using Keras API With a Binary Classification Dataset\n",
    "\n",
    "The code snippet provided below demonstrates a simple example of using the PyTorch framework to build, train, and make predictions with a neural network model.\n",
    "\"\"\"\n",
    "\n",
    "# Generate a synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model architecture\n",
    "# The model consists of two fully connected (Dense) layers.\n",
    "model = Sequential([ \n",
    "    Dense(10, activation='sigmoid', input_shape=(10,)), # The first layer has 10 units and uses the sigmoid activation function. The input shape (10,) specifies that each input sample has 10 features.\n",
    "    Dense(1, activation='sigmoid') # The second layer has 1 unit and also uses the sigmoid activation function.\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy']) #'sgd'represents `Stochastic Gradient Descent`\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Print the predicted probabilities for the first 10 samples\n",
    "print(\"Predicted Probabilities:\")\n",
    "for i in range(10):\n",
    "    print(predictions[i])\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "binary_predictions = [1 if pred >= 0.5 else 0 for pred in predictions]\n",
    "\n",
    "# Print the binary predictions for the first 10 samples\n",
    "print(\"\\nBinary Predictions:\")\n",
    "for i in range(10):\n",
    "    print(binary_predictions[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential #  Sequential model\n",
    "from tensorflow.keras.layers import Dense # Fully connected layers\n",
    "import torch\n",
    "import torch.nn as nn # PyTorch neural network module\n",
    "import torch.optim as optim # Optimizers for training\n",
    "from sklearn.datasets import make_classification # Generate synthetic dataset\n",
    "from sklearn.model_selection import train_test_split # Train-test split\n",
    "from sklearn.preprocessing import StandardScaler # Standardize features\n",
    "\n",
    "\"\"\"\n",
    "PyTorch with A Regression Dataset\n",
    "\n",
    "The code snippet provided below demonstrates a simple example of using the PyTorch framework to build, train, and make predictions with a neural network model.\n",
    "\"\"\"\n",
    "# Define the input data\n",
    "x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
    "y = torch.tensor([2, 4, 6, 8, 10], dtype=torch.float32)\n",
    "\n",
    "# Define the model architecture\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad() # The optimizer's gradients are reset to zero to avoid accumulating gradients from previous iterations.\n",
    "    outputs = model(x.unsqueeze(1)) # The input features are passed through the model to obtain the predicted outputs.\n",
    "    loss = criterion(outputs.squeeze(1), y) # The loss between the predicted outputs and the true target values is calculated.\n",
    "    loss.backward() # Backpropagation is performed by calling loss.backward() to compute the gradients of the loss with respect to the model's parameters.\n",
    "    optimizer.step() # The optimizer updates the model's parameters using optimizer.step(), adjusting the weights and biases based on the computed gradients.\n",
    "\n",
    "# Use the trained model to make predictions on a new set of input features [6, 7, 8, 9, 10]\n",
    "predictions = model(torch.tensor([6, 7, 8, 9, 10], dtype=torch.float32).unsqueeze(1)) \n",
    "print(predictions.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8628d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential #  Sequential model\n",
    "from tensorflow.keras.layers import Dense # Fully connected layers\n",
    "import torch\n",
    "import torch.nn as nn # PyTorch neural network module\n",
    "import torch.optim as optim # Optimizers for training\n",
    "from sklearn.datasets import make_classification # Generate synthetic dataset\n",
    "from sklearn.model_selection import train_test_split # Train-test split\n",
    "from sklearn.preprocessing import StandardScaler # Standardize features\n",
    "\n",
    "\"\"\"\n",
    "Exercise 1 - TensorFlow using Keras API with a regression dataset\n",
    "Based on the given data below, complete the following tasks:\n",
    "\n",
    "Create a sequential model with a single dense layer\n",
    "Compile the model with the specified optimizer, loss function, and metrics: optimizer='sgd', loss='mean_squared_error', metrics=['mean_squared_error']\n",
    "Modify the number of epochs to 20 during model training.\n",
    "Evaluate the model\n",
    "Use the trained model to make predictions on the test data (test_data)\n",
    "\"\"\"\n",
    "# Given data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 8, 10]\n",
    "test_data = [6, 7, 8, 9, 10]\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(1, input_shape=(1,))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, epochs=20)\n",
    "\n",
    "# Evaluate the model and get the mean squared error\n",
    "_, mse = model.evaluate(x, y)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "predictions = model.predict(test_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab25a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential #  Sequential model\n",
    "from tensorflow.keras.layers import Dense # Fully connected layers\n",
    "import torch\n",
    "import torch.nn as nn # PyTorch neural network module\n",
    "import torch.optim as optim # Optimizers for training\n",
    "from sklearn.datasets import make_classification # Generate synthetic dataset\n",
    "from sklearn.model_selection import train_test_split # Train-test split\n",
    "from sklearn.preprocessing import StandardScaler # Standardize features\n",
    "\n",
    "\"\"\"\n",
    "Exercise 2 - Pytorch with a binary classification dataset\n",
    "Based on the given data below, complete the following tasks:\n",
    "\n",
    "Use BCELoss() to be the loss function class. BCELoss() represents binary cross-entropy loss.\n",
    "Choose the SGD (Stochastic Gradient Descent) to be the optimizer.\n",
    "Train the model with 10 epochs.\n",
    "Use the trained model to make prediction on the test data (test_data)\n",
    "\"\"\"\n",
    "\n",
    "# Define the model architecture\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNet()\n",
    "\n",
    "# Given data\n",
    "X = torch.randn(1000, 10)\n",
    "y = torch.randint(0, 2, (1000, 1)).float()\n",
    "test_data = torch.randn(200, 10)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "predictions = model(test_data)\n",
    "predictions = predictions.detach().numpy()\n",
    "\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
